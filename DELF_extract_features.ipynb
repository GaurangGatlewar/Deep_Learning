{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Extracts DELF features from a list of images, saving them to file.\n",
    "\n",
    "The images must be in JPG format. The program checks if descriptors already\n",
    "exist, and skips computation for those.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from tensorflow.python.platform import app\n",
    "from delf import delf_config_pb2\n",
    "from delf import feature_extractor\n",
    "from delf import feature_io\n",
    "\n",
    "cmd_args = None\n",
    "\n",
    "# Extension of feature files.\n",
    "_DELF_EXT = '.delf'\n",
    "\n",
    "# Pace to report extraction log.\n",
    "_STATUS_CHECK_ITERATIONS = 100\n",
    "\n",
    "\n",
    "def _ReadImageList(list_path):\n",
    "  \"\"\"Helper function to read image paths.\n",
    "  Args:\n",
    "    list_path: Path to list of images, one image path per line.\n",
    "  Returns:\n",
    "    image_paths: List of image paths.\n",
    "  \"\"\"\n",
    "  with tf.gfile.GFile(list_path, 'r') as f:\n",
    "    image_paths = f.readlines()\n",
    "  image_paths = [entry.rstrip() for entry in image_paths]\n",
    "  return image_paths\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  # Read list of images.\n",
    "  tf.logging.info('Reading list of images...')\n",
    "  image_paths = _ReadImageList(cmd_args.list_images_path)\n",
    "  num_images = len(image_paths)\n",
    "  tf.logging.info('done! Found %d images', num_images)\n",
    "\n",
    "  # Parse DelfConfig proto.\n",
    "  config = delf_config_pb2.DelfConfig()\n",
    "  with tf.gfile.FastGFile(cmd_args.config_path, 'r') as f:\n",
    "    text_format.Merge(f.read(), config)\n",
    "\n",
    "  # Create output directory if necessary.\n",
    "  if not os.path.exists(cmd_args.output_dir):\n",
    "    os.makedirs(cmd_args.output_dir)\n",
    "\n",
    "  # Tell TensorFlow that the model will be built into the default Graph.\n",
    "  with tf.Graph().as_default():\n",
    "    # Reading list of images.\n",
    "    filename_queue = tf.train.string_input_producer(image_paths, shuffle=False)\n",
    "    reader = tf.WholeFileReader()\n",
    "    _, value = reader.read(filename_queue)\n",
    "    image_tf = tf.image.decode_jpeg(value, channels=3)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      # Initialize variables.\n",
    "      init_op = tf.global_variables_initializer()\n",
    "      sess.run(init_op)\n",
    "\n",
    "      # Loading model that will be used.\n",
    "      tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],\n",
    "                                 config.model_path)\n",
    "      graph = tf.get_default_graph()\n",
    "      input_image = graph.get_tensor_by_name('input_image:0')\n",
    "      input_score_threshold = graph.get_tensor_by_name('input_abs_thres:0')\n",
    "      input_image_scales = graph.get_tensor_by_name('input_scales:0')\n",
    "      input_max_feature_num = graph.get_tensor_by_name(\n",
    "          'input_max_feature_num:0')\n",
    "      boxes = graph.get_tensor_by_name('boxes:0')\n",
    "      raw_descriptors = graph.get_tensor_by_name('features:0')\n",
    "      feature_scales = graph.get_tensor_by_name('scales:0')\n",
    "      attention_with_extra_dim = graph.get_tensor_by_name('scores:0')\n",
    "      attention = tf.reshape(attention_with_extra_dim,\n",
    "                             [tf.shape(attention_with_extra_dim)[0]])\n",
    "\n",
    "      locations, descriptors = feature_extractor.DelfFeaturePostProcessing(\n",
    "          boxes, raw_descriptors, config)\n",
    "\n",
    "      # Start input enqueue threads.\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      start = time.clock()\n",
    "      for i in range(num_images):\n",
    "        # Write to log-info once in a while.\n",
    "        if i == 0:\n",
    "          tf.logging.info('Starting to extract DELF features from images...')\n",
    "        elif i % _STATUS_CHECK_ITERATIONS == 0:\n",
    "          elapsed = (time.clock() - start)\n",
    "          tf.logging.info('Processing image %d out of %d, last %d '\n",
    "                          'images took %f seconds', i, num_images,\n",
    "                          _STATUS_CHECK_ITERATIONS, elapsed)\n",
    "          start = time.clock()\n",
    "\n",
    "        # # Get next image.\n",
    "        im = sess.run(image_tf)\n",
    "\n",
    "        # If descriptor already exists, skip its computation.\n",
    "        out_desc_filename = os.path.splitext(os.path.basename(\n",
    "            image_paths[i]))[0] + _DELF_EXT\n",
    "        out_desc_fullpath = os.path.join(cmd_args.output_dir, out_desc_filename)\n",
    "        if tf.gfile.Exists(out_desc_fullpath):\n",
    "          tf.logging.info('Skipping %s', image_paths[i])\n",
    "          continue\n",
    "\n",
    "        # Extract and save features.\n",
    "        (locations_out, descriptors_out, feature_scales_out,\n",
    "         attention_out) = sess.run(\n",
    "             [locations, descriptors, feature_scales, attention],\n",
    "             feed_dict={\n",
    "                 input_image:\n",
    "                     im,\n",
    "                 input_score_threshold:\n",
    "                     config.delf_local_config.score_threshold,\n",
    "                 input_image_scales:\n",
    "                     list(config.image_scales),\n",
    "                 input_max_feature_num:\n",
    "                     config.delf_local_config.max_feature_num\n",
    "             })\n",
    "\n",
    "        feature_io.WriteToFile(out_desc_fullpath, locations_out,\n",
    "                               feature_scales_out, descriptors_out,\n",
    "                               attention_out)\n",
    "\n",
    "      # Finalize enqueue threads.\n",
    "      coord.request_stop()\n",
    "      coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register('type', 'bool', lambda v: v.lower() == 'true')\n",
    "  parser.add_argument(\n",
    "      '--config_path',\n",
    "      type=str,\n",
    "      default='delf_config_example.pbtxt',\n",
    "      help=\"\"\"\n",
    "      Path to DelfConfig proto text file with configuration to be used for DELF\n",
    "      extraction.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--list_images_path',\n",
    "      type=str,\n",
    "      default='list_images.txt',\n",
    "      help=\"\"\"\n",
    "      Path to list of images whose DELF features will be extracted.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--output_dir',\n",
    "      type=str,\n",
    "      default='/beegfs/gvg228/GLRC/train_delf',\n",
    "      help=\"\"\"\n",
    "      Directory where DELF features will be written to. Each image's features\n",
    "      will be written to a file with same name, and extension replaced by .delf.\n",
    "      \"\"\")\n",
    "  cmd_args, unparsed = parser.parse_known_args()\n",
    "  app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
